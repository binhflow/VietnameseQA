{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WikiQA-Bertv2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meO7ZaISZfZ1",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhdjgZWAZ60C",
        "colab_type": "text"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Hub Authors.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHQH4OCHZ9bq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copyright 2018 The TensorFlow Hub Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# =============================================================================="
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "191zq3ZErihP",
        "colab_type": "code",
        "outputId": "b9ba5788-a358-4aa8-fce2-8e2c74e082c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "import datetime\n",
        "import json\n",
        "import os\n",
        "import pprint\n",
        "import random\n",
        "import string\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "\n",
        "assert 'COLAB_TPU_ADDR' in os.environ, 'ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!'\n",
        "TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "print('TPU address is', TPU_ADDRESS)\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "with tf.Session(TPU_ADDRESS) as session:\n",
        "  print('TPU devices:')\n",
        "  pprint.pprint(session.list_devices())\n",
        "\n",
        "  # Upload credentials to TPU.\n",
        "  with open('/content/adc.json', 'r') as f:\n",
        "    auth_info = json.load(f)\n",
        "  tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n",
        "  # Now credentials are set for all future sessions on this TPU."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TPU address is grpc://10.95.83.234:8470\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "TPU devices:\n",
            "[_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 2204676422108459207),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 11313756108960186354),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 17654255306167292778),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 14351922719313144005),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 4973633010266650051),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 7073275947122365795),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 602665409412993700),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 1008039598861276824),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 17388383968304458528),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 17868044357804238199),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 12669223275291908199)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wzwke0sxS6W",
        "colab_type": "code",
        "outputId": "3d1f6001-3372-4af9-ec0d-bbec12bee9b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "source": [
        "import sys\n",
        "\n",
        "!test -d bert_repo || git clone https://github.com/google-research/bert bert_repo\n",
        "if not 'bert_repo' in sys.path:\n",
        "  sys.path += ['bert_repo']\n",
        "\n",
        "# import python modules defined by BERT\n",
        "import modeling\n",
        "import optimization\n",
        "import run_classifier\n",
        "import run_classifier_with_tfhub\n",
        "import tokenization\n",
        "\n",
        "# import tfhub \n",
        "import tensorflow_hub as hub"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'bert_repo'...\n",
            "remote: Enumerating objects: 336, done.\u001b[K\n",
            "remote: Total 336 (delta 0), reused 0 (delta 0), pack-reused 336\u001b[K\n",
            "Receiving objects: 100% (336/336), 283.40 KiB | 3.94 MiB/s, done.\n",
            "Resolving deltas: 100% (185/185), done.\n",
            "WARNING:tensorflow:From bert_repo/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYkaAlJNfhul",
        "colab_type": "code",
        "outputId": "e769835d-b48c-486e-ee8c-4eaced0de5b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "TASK = 'WikiQAv5.0'\n",
        "BUCKET = 'bert-logs-zalo'\n",
        "assert BUCKET, 'Must specify an existing GCS bucket name'\n",
        "OUTPUT_DIR = 'gs://{}/bert-tfhub/models/{}'.format(BUCKET, TASK)\n",
        "tf.gfile.MakeDirs(OUTPUT_DIR)\n",
        "print('***** Model output directory: {} *****'.format(OUTPUT_DIR))\n",
        "BERT_MODEL = 'multi_cased_L-12_H-768_A-12' \n",
        "BERT_MODEL_HUB = 'https://tfhub.dev/google/bert_' + BERT_MODEL + '/1'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Model output directory: gs://bert-logs-zalo/bert-tfhub/models/WikiQAv5.0 *****\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TylDOYd-6AH-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = run_classifier_with_tfhub.create_tokenizer_from_hub_module(BERT_MODEL_HUB)\n",
        "tokenizer.tokenize('Học máy ( tiếng Anh : \" machine learning \" ) là một lĩnh vực của trí tuệ nhân tạo')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCLgvoS6mVJU",
        "colab_type": "text"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRuzSgO-myCE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "np-xtEScq257",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def download(link, name):\n",
        "  dataset = tf.keras.utils.get_file(\n",
        "      fname=name+\".zip\", \n",
        "      origin=link, \n",
        "      extract=True)\n",
        "  with tf.gfile.GFile(os.path.join(os.path.dirname(dataset), name+'.json'), \"r\") as f:\n",
        "    data_dict = json.load(f)\n",
        "    return data_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KwnPn_NCAzE",
        "colab_type": "code",
        "outputId": "073ca715-f406-492b-f41d-dab0a48a4d62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "train_dict = download('https://dl.challenge.zalo.ai/ZAC2019_VietnameseWikiQA/train.zip','train')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://dl.challenge.zalo.ai/ZAC2019_VietnameseWikiQA/train.zip\n",
            "2506752/2504567 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fujrSLn0D9LP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame.from_dict(train_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKkav-F7SqXo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['label']=np.where(df['label']==True,1,0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxlW4Twl4HT1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, dev = train_test_split(df, test_size=0.4,random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8T5WcAa5F0A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_InputExamples = train.apply(lambda x: run_classifier.InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this example\n",
        "                                                                   text_a = x['question'], \n",
        "                                                                   text_b = x['text'], \n",
        "                                                                   label = x['label']), axis = 1)\n",
        "dev_InputExamples = dev.apply(lambda x: run_classifier.InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this example\n",
        "                                                                   text_a = x['question'], \n",
        "                                                                   text_b = x['text'], \n",
        "                                                                   label = x['label']), axis = 1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoOCXGDPg7NH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_list = [0, 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqQ_LHyzcoYW",
        "colab_type": "text"
      },
      "source": [
        "Also we initilize our hyperprams, prepare the training data and initialize TPU config."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYVYULZiKvUi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_BATCH_SIZE = 16\n",
        "EVAL_BATCH_SIZE = 8\n",
        "PREDICT_BATCH_SIZE = 8\n",
        "LEARNING_RATE = 2e-5\n",
        "NUM_TRAIN_EPOCHS = 3.0\n",
        "MAX_SEQ_LENGTH = 256\n",
        "# Warmup is a period of time where hte learning rate \n",
        "# is small and gradually increases--usually helps training.\n",
        "WARMUP_PROPORTION = 0.1\n",
        "# Model configs\n",
        "SAVE_CHECKPOINTS_STEPS = 1000\n",
        "SAVE_SUMMARY_STEPS = 1000\n",
        "\n",
        "# Compute number of train and warmup steps from batch size\n",
        "num_train_steps = int(len(train) / TRAIN_BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
        "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
        "\n",
        "# Setup TPU related config\n",
        "tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_ADDRESS)\n",
        "NUM_TPU_CORES = 8\n",
        "ITERATIONS_PER_LOOP = 1000\n",
        "\n",
        "def get_run_config(output_dir):\n",
        "  return tf.contrib.tpu.RunConfig(\n",
        "    cluster=tpu_cluster_resolver,\n",
        "    model_dir=output_dir,\n",
        "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS,\n",
        "    tpu_config=tf.contrib.tpu.TPUConfig(\n",
        "        iterations_per_loop=ITERATIONS_PER_LOOP,\n",
        "        num_shards=NUM_TPU_CORES,\n",
        "        per_host_input_for_training=tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3iFMeqLaSll",
        "colab_type": "text"
      },
      "source": [
        "# Fine-tune and Run Predictions on a pretrained BERT Model from TF Hub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXyJRc0OIHEU",
        "colab_type": "text"
      },
      "source": [
        "This section demonstrates fine-tuning from a pre-trained BERT TF Hub module and running predictions.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14Cl9AKjRG1c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(is_training, input_ids, input_mask, segment_ids, labels,\n",
        "                 num_labels, bert_hub_module_handle):\n",
        "  \"\"\"Creates a classification model.\"\"\"\n",
        "  tags = set()\n",
        "  if is_training:\n",
        "    tags.add(\"train\")\n",
        "  bert_module = hub.Module(bert_hub_module_handle, tags=tags, trainable=True)\n",
        "  bert_inputs = dict(\n",
        "      input_ids=input_ids,\n",
        "      input_mask=input_mask,\n",
        "      segment_ids=segment_ids)\n",
        "  bert_outputs = bert_module(\n",
        "      inputs=bert_inputs,\n",
        "      signature=\"tokens\",\n",
        "      as_dict=True)\n",
        "\n",
        "  # In the demo, we are doing a simple classification task on the entire\n",
        "  # segment.\n",
        "  #\n",
        "  # If you want to use the token-level output, use\n",
        "  # bert_outputs[\"sequence_output\"] instead.\n",
        "  output_layer = bert_outputs[\"pooled_output\"]\n",
        "\n",
        "  hidden_size = output_layer.shape[-1].value\n",
        "\n",
        "  output_weights = tf.get_variable(\n",
        "      \"output_weights\", [num_labels, hidden_size],\n",
        "      initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "\n",
        "  output_bias = tf.get_variable(\n",
        "      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
        "\n",
        "  with tf.variable_scope(\"loss\"):\n",
        "    if is_training:\n",
        "      # I.e., 0.1 dropout\n",
        "      output_layer = tf.nn.dropout(output_layer, keep_prob=0.5)\n",
        "\n",
        "    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
        "    logits = tf.nn.bias_add(logits, output_bias)\n",
        "    probabilities = tf.nn.softmax(logits, axis=-1)\n",
        "    log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
        "\n",
        "    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
        "\n",
        "    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
        "    loss = tf.reduce_mean(per_example_loss)\n",
        "\n",
        "    return (loss, per_example_loss, logits, probabilities)\n",
        "\n",
        "def model_fn_builder(num_labels, learning_rate, num_train_steps,\n",
        "                     num_warmup_steps, use_tpu, bert_hub_module_handle):\n",
        "  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
        "\n",
        "  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
        "    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
        "\n",
        "    tf.logging.info(\"*** Features ***\")\n",
        "    for name in sorted(features.keys()):\n",
        "      tf.logging.info(\"  name = %s, shape = %s\" % (name, features[name].shape))\n",
        "\n",
        "    input_ids = features[\"input_ids\"]\n",
        "    input_mask = features[\"input_mask\"]\n",
        "    segment_ids = features[\"segment_ids\"]\n",
        "    label_ids = features[\"label_ids\"]\n",
        "\n",
        "    is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
        "\n",
        "    (total_loss, per_example_loss, logits, probabilities) = create_model(\n",
        "        is_training, input_ids, input_mask, segment_ids, label_ids, num_labels,\n",
        "        bert_hub_module_handle)\n",
        "\n",
        "    output_spec = None\n",
        "\n",
        "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "\n",
        "      train_op = optimization.create_optimizer(\n",
        "          total_loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu)\n",
        "      output_spec = tf.contrib.tpu.TPUEstimatorSpec(\n",
        "          mode=mode,\n",
        "          loss=total_loss,\n",
        "          train_op=train_op)\n",
        "    elif mode == tf.estimator.ModeKeys.EVAL:\n",
        "\n",
        "      def metric_fn(per_example_loss, label_ids, logits):\n",
        "        predictions = tf.argmax(logits, axis=-1, output_type=tf.int32)\n",
        "        accuracy = tf.metrics.accuracy(label_ids, predictions)\n",
        "        loss = tf.metrics.mean(per_example_loss)\n",
        "        f1_score = tf.contrib.metrics.f1_score(label_ids, predictions)\n",
        "        return {\n",
        "            \"eval_accuracy\": accuracy,\n",
        "            \"eval_loss\": loss,\n",
        "            \"f1_score\": f1_score\n",
        "        }\n",
        "\n",
        "      eval_metrics = (metric_fn, [per_example_loss, label_ids, logits])\n",
        "      output_spec = tf.contrib.tpu.TPUEstimatorSpec(\n",
        "          mode=mode,\n",
        "          loss=total_loss,\n",
        "          eval_metrics=eval_metrics)\n",
        "    elif mode == tf.estimator.ModeKeys.PREDICT:\n",
        "      output_spec = tf.contrib.tpu.TPUEstimatorSpec(\n",
        "          mode=mode, predictions={\"probabilities\": probabilities})\n",
        "    else:\n",
        "      raise ValueError(\n",
        "          \"Only TRAIN, EVAL and PREDICT modes are supported: %s\" % (mode))\n",
        "\n",
        "    return output_spec\n",
        "\n",
        "  return model_fn\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwcsdbLuIX2I",
        "colab_type": "code",
        "outputId": "71d7ff5d-558a-4578-9e4a-4d21919d1a92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        }
      },
      "source": [
        "# Force TF Hub writes to the GS bucket we provide.\n",
        "os.environ['TFHUB_CACHE_DIR'] = OUTPUT_DIR\n",
        "\n",
        "model_fn = model_fn_builder(\n",
        "  num_labels=len(label_list),\n",
        "  learning_rate=LEARNING_RATE,\n",
        "  num_train_steps=num_train_steps,\n",
        "  num_warmup_steps=num_warmup_steps,\n",
        "  use_tpu=True,\n",
        "  bert_hub_module_handle=BERT_MODEL_HUB\n",
        ")\n",
        "\n",
        "estimator_from_tfhub = tf.contrib.tpu.TPUEstimator(\n",
        "  use_tpu=True,\n",
        "  model_fn=model_fn,\n",
        "  config=get_run_config(OUTPUT_DIR),\n",
        "  train_batch_size=TRAIN_BATCH_SIZE,\n",
        "  eval_batch_size=EVAL_BATCH_SIZE,\n",
        "  predict_batch_size=PREDICT_BATCH_SIZE,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f7531c46bf8>) includes params argument, but params are not passed to Estimator.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f7531c46bf8>) includes params argument, but params are not passed to Estimator.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://bert-logs-zalo/bert-tfhub/models/WikiQAv5.0', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.95.83.234:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "isolate_session_state: true\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f7536fce5c0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.95.83.234:8470', '_evaluation_master': 'grpc://10.95.83.234:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu_cluster_resolver.TPUClusterResolver object at 0x7f7536fd2f98>}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://bert-logs-zalo/bert-tfhub/models/WikiQAv5.0', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.95.83.234:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "isolate_session_state: true\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f7536fce5c0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.95.83.234:8470', '_evaluation_master': 'grpc://10.95.83.234:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu_cluster_resolver.TPUClusterResolver object at 0x7f7536fd2f98>}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGVYj_rlcDhc",
        "colab_type": "text"
      },
      "source": [
        "At this point, you can now fine-tune the model, evaluate it, and run predictions on it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5U_c8s2AvhgL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train the model\n",
        "def model_train(estimator):\n",
        "  # We'll set sequences to be at most 128 tokens long.\n",
        "  train_features = run_classifier.convert_examples_to_features(\n",
        "      train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "  print('***** Started training at {} *****'.format(datetime.datetime.now()))\n",
        "  print('  Num examples = {}'.format(len(train)))\n",
        "  print('  Batch size = {}'.format(TRAIN_BATCH_SIZE))\n",
        "  tf.logging.info(\"  Num steps = %d\", num_train_steps)\n",
        "  train_input_fn = run_classifier.input_fn_builder(\n",
        "      features=train_features,\n",
        "      seq_length=MAX_SEQ_LENGTH,\n",
        "      is_training=True,\n",
        "      drop_remainder=True)\n",
        "  estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
        "  print('***** Finished training at {} *****'.format(datetime.datetime.now()))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRhzyk4_WD2n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_train(estimator_from_tfhub)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoXRtSPZvdiS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_eval(estimator):\n",
        "  # Eval the model.\n",
        "  eval_features = run_classifier.convert_examples_to_features(\n",
        "      dev_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "  print('***** Started evaluation at {} *****'.format(datetime.datetime.now()))\n",
        "  print('  Num examples = {}'.format(len(dev)))\n",
        "  print('  Batch size = {}'.format(EVAL_BATCH_SIZE))\n",
        "\n",
        "  # Eval will be slightly WRONG on the TPU because it will truncate\n",
        "  # the last batch.\n",
        "  eval_steps = int(len(dev) / EVAL_BATCH_SIZE)\n",
        "  eval_input_fn = run_classifier.input_fn_builder(\n",
        "      features=eval_features,\n",
        "      seq_length=MAX_SEQ_LENGTH,\n",
        "      is_training=False,\n",
        "      drop_remainder=True)\n",
        "  result = estimator.evaluate(input_fn=eval_input_fn, steps=eval_steps)\n",
        "  print('***** Finished evaluation at {} *****'.format(datetime.datetime.now()))\n",
        "  output_eval_file = os.path.join(OUTPUT_DIR, \"eval_results.txt\")\n",
        "  with tf.gfile.GFile(output_eval_file, \"w\") as writer:\n",
        "    print(\"***** Eval results *****\")\n",
        "    for key in sorted(result.keys()):\n",
        "      print('  {} = {}'.format(key, str(result[key])))\n",
        "      writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLQehBr4WHjj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_eval(estimator_from_tfhub)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3_afEMR3dfa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_predict(estimator, prediction_examples):\n",
        "  eval_features = run_classifier.convert_examples_to_features(\n",
        "      prediction_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "  predict_input_fn = run_classifier.input_fn_builder(features=eval_features, seq_length=MAX_SEQ_LENGTH, is_training=False, drop_remainder=True)\n",
        "  predictions = estimator.predict(predict_input_fn)\n",
        "  pred_dict = {}\n",
        "  pred_dict[\"question\"] = [] \n",
        "  pred_dict[\"text\"] = [] \n",
        "  pred_dict[\"label\"] = [] \n",
        "  pred_dict[\"pred\"] = []\n",
        "  for example, prediction in zip(prediction_examples, predictions):\n",
        "    pred_dict[\"question\"].append(example.text_a)\n",
        "    pred_dict[\"text\"].append(example.text_b)\n",
        "    pred_dict[\"label\"].append(example.label)\n",
        "    pred_dict[\"pred\"].append(np.squeeze(np.argmax(prediction['probabilities'], axis=-1)))\n",
        "  #   print('text_a: %s\\ntext_b: %s\\nlabel:%s\\nprediction:%s\\n' % (example.text_a, example.text_b, str(example.label), prediction['labels']))\n",
        "  df = pd.DataFrame.from_dict(pred_dict)\n",
        "  return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynDmeatCWLJK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_pred = model_predict(estimator_from_tfhub, dev_InputExamples)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcVjbQoeln2o",
        "colab_type": "code",
        "outputId": "4ce18b49-dac0-471e-c36a-17f8327bf8da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "source": [
        "from sklearn.metrics import f1_score, classification_report, accuracy_score, confusion_matrix\n",
        "print('***F1 SCORE DEV***')\n",
        "print(f1_score(df_pred['label'],df_pred['pred']))\n",
        "print('***REPORT DEV***')\n",
        "print(classification_report(df_pred['label'],df_pred['pred']))\n",
        "print('***CONFUSION MATRIX***')\n",
        "print(confusion_matrix(df_pred['label'],df_pred['pred']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***F1 SCORE DEV***\n",
            "0.7999999999999999\n",
            "***REPORT DEV***\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.92      0.91       126\n",
            "           1       0.81      0.79      0.80        56\n",
            "\n",
            "    accuracy                           0.88       182\n",
            "   macro avg       0.86      0.85      0.86       182\n",
            "weighted avg       0.88      0.88      0.88       182\n",
            "\n",
            "***CONFUSION MATRIX***\n",
            "[[116  10]\n",
            " [ 12  44]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdEivyZy6DQl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_pred_train = model_predict(estimator_from_tfhub, train_InputExamples)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtsY0oEXAe7D",
        "colab_type": "code",
        "outputId": "dcf8c112-efd2-4582-dae5-331500c34bad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "print('***ACCURACY TRAIN***')\n",
        "print(accuracy_score(df_pred_train['label'],df_pred_train['pred']))\n",
        "print('***F1 SCORE TRAIN***')\n",
        "print(f1_score(df_pred_train['label'],df_pred_train['pred']))\n",
        "print('***REPORT TRAIN***')\n",
        "print(classification_report(df_pred_train['label'],df_pred_train['pred']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***ACCURACY TRAIN***\n",
            "0.9818141247350217\n",
            "***F1 SCORE TRAIN***\n",
            "0.971528384279476\n",
            "***REPORT TRAIN***\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.99     12244\n",
            "           1       0.96      0.98      0.97      5682\n",
            "\n",
            "    accuracy                           0.98     17926\n",
            "   macro avg       0.98      0.98      0.98     17926\n",
            "weighted avg       0.98      0.98      0.98     17926\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbHMheIfLHro",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_pred['text_len'] = df_pred['text'].apply(lambda x: len(x.split(' ')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWvlVGnoLd9_",
        "colab_type": "code",
        "outputId": "0e39550d-6fc5-4aa6-9981-84b391d9c580",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        }
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "sns.distplot(df_pred[(df_pred['label']==1)&(df_pred['pred']==1)]['text_len'])\n",
        "sns.distplot(df_pred[(df_pred['label']==1)&(df_pred['pred']==0)]['text_len'])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEHCAYAAACncpHfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfwmUJlyH0q-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "er = df_pred[(df_pred['label']==1)&(df_pred['pred']==0)].head(100).reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7pwHEIjSYyw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "er['question_tok'] = er['question'].apply(lambda x:tokenizer.tokenize(x))\n",
        "er['text_tok'] = er['text'].apply(lambda x:tokenizer.tokenize(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umay2OOMSB1O",
        "colab_type": "code",
        "outputId": "d72d2777-8316-4faa-9e5e-d512461eead7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        }
      },
      "source": [
        "er.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>pred</th>\n",
              "      <th>text_len</th>\n",
              "      <th>question_tok</th>\n",
              "      <th>text_tok</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bettoven viết bản sonat ánh trăng để tặng cho ai</td>\n",
              "      <td>Ludwig van Beethoven viết bản sonata này dành ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>64</td>\n",
              "      <td>[Bet, ##tov, ##en, viết, bản, sona, ##t, ánh, ...</td>\n",
              "      <td>[Ludwig, van, Beethoven, viết, bản, sona, ##ta...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Biểu tượng của Canada</td>\n",
              "      <td>Cô và Kevin Reynolds là cả hai biểu tượng trượ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>[Bi, ##ểu, tượng, của, Canada]</td>\n",
              "      <td>[Cô, và, Kevin, Reynolds, là, cả, hai, biểu, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ấp Hà Đông, tiền thân của làng hoa đầu tiên ở ...</td>\n",
              "      <td>Diện tích đất khai phá ban đầu ở Ấp Hà Đông ch...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>100</td>\n",
              "      <td>[Ấ, ##p, Hà, Đông, ,, tiền, thân, của, làng, h...</td>\n",
              "      <td>[Di, ##ện, tích, đất, khai, phá, ban, đầu, ở, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Thành phố nào là thủ đô của Ba Lan</td>\n",
              "      <td>Vác-sa-va là thủ đô của Ba Lan</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>[Thành, phố, nào, là, thủ, đô, của, Ba, Lan]</td>\n",
              "      <td>[V, ##ác, -, sa, -, va, là, thủ, đô, của, Ba, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Pháp tấn công xâm lược Việt Nam vào ngày tháng...</td>\n",
              "      <td>Năm 1958, thực dân Pháp nổ súng tấn công bán đ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>51</td>\n",
              "      <td>[Pháp, tấn, công, xâm, lược, Việt, Nam, vào, n...</td>\n",
              "      <td>[Năm, 1958, ,, thực, dân, Pháp, nổ, súng, tấn,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            question  ...                                           text_tok\n",
              "0   Bettoven viết bản sonat ánh trăng để tặng cho ai  ...  [Ludwig, van, Beethoven, viết, bản, sona, ##ta...\n",
              "1                              Biểu tượng của Canada  ...  [Cô, và, Kevin, Reynolds, là, cả, hai, biểu, t...\n",
              "2  Ấp Hà Đông, tiền thân của làng hoa đầu tiên ở ...  ...  [Di, ##ện, tích, đất, khai, phá, ban, đầu, ở, ...\n",
              "3                 Thành phố nào là thủ đô của Ba Lan  ...  [V, ##ác, -, sa, -, va, là, thủ, đô, của, Ba, ...\n",
              "4  Pháp tấn công xâm lược Việt Nam vào ngày tháng...  ...  [Năm, 1958, ,, thực, dân, Pháp, nổ, súng, tấn,...\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U36NJS7yKwCv",
        "colab_type": "code",
        "outputId": "755b1a2f-b2df-48ad-8842-4f8898019c26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i in range(0,len(er)):\n",
        "  print('question: %s\\nanswer: %s\\nprediction:%s\\nquestion_tok: %s\\ntext_tok: %s\\n' % (er.loc[i]['question'],er.loc[i]['text'],er.loc[i]['pred'],er.loc[i]['question_tok'],er.loc[i]['text_tok']))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "question: Bettoven viết bản sonat ánh trăng để tặng cho ai\n",
            "answer: Ludwig van Beethoven viết bản sonata này dành cho cô học sinh dương cầm 17 tuổi của ông Gräfin Giulietta Guicciardi (1784–1856) vào năm 1801 và sau khi ông mất vài năm thì bản sonate được nhà phê bình âm nhạc Ludwig Rellstab đặt cho cái tên phổ biến như bây giờ, ông đã so sánh bản nhạc với ánh trăng trên hồ Lucerne.\n",
            "prediction:0\n",
            "question_tok: ['Bet', '##tov', '##en', 'viết', 'bản', 'sona', '##t', 'ánh', 'tr', '##ăng', 'để', 'tặng', 'cho', 'ai']\n",
            "text_tok: ['Ludwig', 'van', 'Beethoven', 'viết', 'bản', 'sona', '##ta', 'này', 'dành', 'cho', 'cô', 'học', 'sinh', 'dương', 'cầm', '17', 'tuổi', 'của', 'ông', 'Gräfin', 'G', '##iul', '##iet', '##ta', 'G', '##ui', '##ccia', '##rdi', '(', '1784', '[UNK]', '1856', ')', 'vào', 'năm', '1801', 'và', 'sau', 'khi', 'ông', 'mất', 'vài', 'năm', 'thì', 'bản', 'sona', '##te', 'được', 'nhà', 'phê', 'bình', 'âm', 'nhạc', 'Ludwig', 'Re', '##lls', '##tab', 'đặt', 'cho', 'cái', 'tên', 'phổ', 'biến', 'như', 'b', '##ây', 'giờ', ',', 'ông', 'đã', 'so', 's', '##ánh', 'bản', 'nhạc', 'với', 'ánh', 'tr', '##ăng', 'trên', 'hồ', 'Luce', '##rne', '.']\n",
            "\n",
            "question: Biểu tượng của Canada\n",
            "answer: Cô và Kevin Reynolds là cả hai biểu tượng trượt băng Canada.\n",
            "prediction:0\n",
            "question_tok: ['Bi', '##ểu', 'tượng', 'của', 'Canada']\n",
            "text_tok: ['Cô', 'và', 'Kevin', 'Reynolds', 'là', 'cả', 'hai', 'biểu', 'tượng', 'tr', '##ư', '##ợt', 'băng', 'Canada', '.']\n",
            "\n",
            "question: Ấp Hà Đông, tiền thân của làng hoa đầu tiên ở Đà Lạt thành lập từ năm nào\n",
            "answer: Diện tích đất khai phá ban đầu ở Ấp Hà Đông chỉ từ vài chục ha lên hàng trăm ha, bà con vừa xây dựng nhà cửa vừa trồng trọt các loại rau hoa mang từ Hà Nội vào. Từ năm 1941, ấp Hà Đông bắt đầu làm ăn phát đạt nhờ nghề trồng hoa và rau cải nầy. Cuối năm 1941, có tất cả 28 gia đình ở ấp Hà Đông, tổng số 100 nhân khẩu. Việc thành lập ấp Hà Đông tạo tiền đề cho hoạt động sản xuất trồng rau và hoa của Đà Lạt sau này.\n",
            "prediction:0\n",
            "question_tok: ['Ấ', '##p', 'Hà', 'Đông', ',', 'tiền', 'thân', 'của', 'làng', 'hoa', 'đầu', 'tiên', 'ở', 'Đà', 'L', '##ạt', 'thành', 'lập', 'từ', 'năm', 'nào']\n",
            "text_tok: ['Di', '##ện', 'tích', 'đất', 'khai', 'phá', 'ban', 'đầu', 'ở', 'Ấ', '##p', 'Hà', 'Đông', 'chỉ', 'từ', 'vài', 'ch', '##ục', 'ha', 'lên', 'hàng', 'tr', '##ăm', 'ha', ',', 'bà', 'con', 'vừa', 'xây', 'dựng', 'nhà', 'cửa', 'vừa', 'trồng', 'tr', '##ọt', 'các', 'loại', 'ra', '##u', 'hoa', 'mang', 'từ', 'Hà', 'Nội', 'vào', '.', 'Từ', 'năm', '1941', ',', 'ấ', '##p', 'Hà', 'Đông', 'bắt', 'đầu', 'làm', 'ăn', 'phát', 'đạt', 'nhờ', 'nghề', 'trồng', 'hoa', 'và', 'ra', '##u', 'cải', 'n', '##ầy', '.', 'Cuối', 'năm', '1941', ',', 'có', 'tất', 'cả', '28', 'gia', 'đình', 'ở', 'ấ', '##p', 'Hà', 'Đông', ',', 'tổng', 'số', '100', 'nhân', 'khẩu', '.', 'Việc', 'thành', 'lập', 'ấ', '##p', 'Hà', 'Đông', 'tạo', 'tiền', 'đề', 'cho', 'hoạt', 'động', 'sản', 'xuất', 'trồng', 'ra', '##u', 'và', 'hoa', 'của', 'Đà', 'L', '##ạt', 'sau', 'này', '.']\n",
            "\n",
            "question: Thành phố nào là thủ đô của Ba Lan\n",
            "answer: Vác-sa-va là thủ đô của Ba Lan\n",
            "prediction:0\n",
            "question_tok: ['Thành', 'phố', 'nào', 'là', 'thủ', 'đô', 'của', 'Ba', 'Lan']\n",
            "text_tok: ['V', '##ác', '-', 'sa', '-', 'va', 'là', 'thủ', 'đô', 'của', 'Ba', 'Lan']\n",
            "\n",
            "question: Pháp tấn công xâm lược Việt Nam vào ngày tháng năm nào\n",
            "answer: Năm 1958, thực dân Pháp nổ súng tấn công bán đảo Sơn Trà (Đà Nẵng), chính thức xâm lược nước ta. Năm 1884, thực dân Pháp buộc triều đình nhà Nguyễn phải ký hòa ước Pa-tơ-nốt, chấp nhận ách thống trị của thực dân Pháp trên toàn bờ cõi Việt Nam.\n",
            "prediction:0\n",
            "question_tok: ['Pháp', 'tấn', 'công', 'xâm', 'lược', 'Việt', 'Nam', 'vào', 'ngày', 'tháng', 'năm', 'nào']\n",
            "text_tok: ['Năm', '1958', ',', 'thực', 'dân', 'Pháp', 'nổ', 'súng', 'tấn', 'công', 'bán', 'đảo', 'Sơn', 'T', '##rà', '(', 'Đà', 'N', '##ẵ', '##ng', ')', ',', 'chính', 'thức', 'xâm', 'lược', 'nước', 'ta', '.', 'Năm', '1884', ',', 'thực', 'dân', 'Pháp', 'buộc', 'triều', 'đình', 'nhà', 'Nguyễn', 'phải', 'ký', 'hòa', 'ước', 'Pa', '-', 't', '##ơ', '-', 'n', '##ốt', ',', 'chấp', 'nhận', 'á', '##ch', 'thống', 'trị', 'của', 'thực', 'dân', 'Pháp', 'trên', 'toàn', 'bờ', 'c', '##õi', 'Việt', 'Nam', '.']\n",
            "\n",
            "question: Cậu vàng là nhân vật trong tác phẩm nào\n",
            "answer: 'Cậu Vàng', chuyển thể từ truyện ngắn 'Lão Hạc' của nhà văn Nam Cao, là phim điện ảnh Việt Nam đầu tiên có diễn viên chính là một chú chó.\n",
            "prediction:0\n",
            "question_tok: ['C', '##ậu', 'vàng', 'là', 'nhân', 'vật', 'trong', 'tác', 'phẩm', 'nào']\n",
            "text_tok: [\"'\", 'C', '##ậu', 'Và', '##ng', \"'\", ',', 'chuyển', 'thể', 'từ', 'truyện', 'ngắn', \"'\", 'L', '##ão', 'Hạ', '##c', \"'\", 'của', 'nhà', 'văn', 'Nam', 'Cao', ',', 'là', 'phim', 'điện', 'ảnh', 'Việt', 'Nam', 'đầu', 'tiên', 'có', 'diễn', 'viên', 'chính', 'là', 'một', 'chú', 'chó', '.']\n",
            "\n",
            "question: Triều đại nhà Lý nước ta có bao nhiêu vị vua\n",
            "answer: Lý Chiêu Hoàng là vị vua thứ 9 và cũng chính là vị vua cuối cùng của triều đại nhà Lý. Bà trị vì đất nước trong 1 năm, kể từ năm 1224 đến 1225. Trong lịch sử Việt Nam, Lý Chiêu Hoàng là người phụ nữ đầu tiên và cũng là duy nhất nắm quyền triều chính. Bà được vua cha là Lý Huệ Tông truyền ngôi, do sự sắp đặt của  Trần Thủ Độ , là người có quyền lực lớn trong triều đình lúc bấy giờ.\n",
            "prediction:0\n",
            "question_tok: ['Triều', 'đại', 'nhà', 'Lý', 'nước', 'ta', 'có', 'bao', 'n', '##hi', '##êu', 'vị', 'vua']\n",
            "text_tok: ['Lý', 'Chi', '##êu', 'Hoàng', 'là', 'vị', 'vua', 'thứ', '9', 'và', 'cũng', 'chính', 'là', 'vị', 'vua', 'cuối', 'cùng', 'của', 'triều', 'đại', 'nhà', 'Lý', '.', 'Bà', 'trị', 'vì', 'đất', 'nước', 'trong', '1', 'năm', ',', 'kể', 'từ', 'năm', '1224', 'đến', '1225', '.', 'Trong', 'lịch', 'sử', 'Việt', 'Nam', ',', 'Lý', 'Chi', '##êu', 'Hoàng', 'là', 'người', 'phụ', 'nữ', 'đầu', 'tiên', 'và', 'cũng', 'là', 'duy', 'nhất', 'nắm', 'quyền', 'triều', 'chính', '.', 'Bà', 'được', 'vua', 'cha', 'là', 'Lý', 'Hu', '##ệ', 'Tông', 'truyền', 'ngôi', ',', 'do', 'sự', 's', '##ắp', 'đặt', 'của', 'Trần', 'Thủ', 'Độ', ',', 'là', 'người', 'có', 'quyền', 'lực', 'lớn', 'trong', 'triều', 'đình', 'lúc', 'b', '##ấy', 'giờ', '.']\n",
            "\n",
            "question: người nào là chủ tịch ủy ban nhân dân của thành phố Sài Gòn\n",
            "answer: Nguyễn Thành Phong (sinh năm 1962) là một chính trị gia người Việt Nam. Ông hiện là Chủ tịch Ủy ban Nhân dân Thành phố Hồ Chí Minh. Trong Đảng Cộng sản Việt Nam, ông hiện giữ chức Ủy viên Ban Chấp hành Trung ương Đảng Cộng sản Việt Nam khóa XII, Phó Bí thư Thành ủy TP Hồ Chí Minh.\n",
            "prediction:0\n",
            "question_tok: ['người', 'nào', 'là', 'chủ', 'tịch', 'ủy', 'ban', 'nhân', 'dân', 'của', 'thành', 'phố', 'Sài', 'Gòn']\n",
            "text_tok: ['Nguyễn', 'Thành', 'Phong', '(', 'sinh', 'năm', '1962', ')', 'là', 'một', 'chính', 'trị', 'gia', 'người', 'Việt', 'Nam', '.', 'Ông', 'hiện', 'là', 'Chủ', 'tịch', 'Ủy', 'ban', 'Nhân', 'dân', 'Thành', 'phố', 'Hồ', 'Chí', 'Minh', '.', 'Trong', 'Đảng', 'Cộng', 'sản', 'Việt', 'Nam', ',', 'ông', 'hiện', 'giữ', 'chức', 'Ủy', 'viên', 'Ban', 'Ch', '##ấp', 'hành', 'Trung', 'ương', 'Đảng', 'Cộng', 'sản', 'Việt', 'Nam', 'khóa', 'XII', ',', 'Phó', 'Bí', 'thư', 'Thành', 'ủy', 'TP', 'Hồ', 'Chí', 'Minh', '.']\n",
            "\n",
            "question: trái đất có bao nhiêu bán cầu\n",
            "answer: Kinh tuyến là một nửa đường tròn trên bề mặt Trái Đất , nối liền hai Địa cực , có độ dài khoảng 20.000  km , chỉ hướng bắc-nam và cắt thẳng góc với đường xích đạo . Mặt phẳng của kinh tuyến 0 ° ( chạy qua đài quan sát thiên văn tại Greenwich thuộc Luân Đôn ) và kinh tuyến 180 ° , chia Trái Đất ra làm hai bán cầu – Bán cầu đông và Bán cầu tây .\n",
            "prediction:0\n",
            "question_tok: ['trái', 'đất', 'có', 'bao', 'n', '##hi', '##êu', 'bán', 'cầu']\n",
            "text_tok: ['Kinh', 'tuyến', 'là', 'một', 'nửa', 'đường', 'tròn', 'trên', 'bề', 'mặt', 'Trái', 'Đất', ',', 'nối', 'liền', 'hai', 'Địa', 'cực', ',', 'có', 'độ', 'dài', 'khoảng', '20', '.', '000', 'km', ',', 'chỉ', 'hướng', 'bắc', '-', 'nam', 'và', 'cắt', 'thẳng', 'g', '##óc', 'với', 'đường', 'x', '##ích', 'đạo', '.', 'Mặt', 'ph', '##ẳng', 'của', 'kinh', 'tuyến', '0', '°', '(', 'chạy', 'qua', 'đài', 'quan', 'sát', 'thiên', 'văn', 'tại', 'Greenwich', 'thuộc', 'Lu', '##ân', 'Đô', '##n', ')', 'và', 'kinh', 'tuyến', '180', '°', ',', 'chia', 'Trái', 'Đất', 'ra', 'làm', 'hai', 'bán', 'cầu', '[UNK]', 'B', '##án', 'cầu', 'đông', 'và', 'B', '##án', 'cầu', 'tây', '.']\n",
            "\n",
            "question: Cách trình bày mâm ngũ quả của người Bắc theo quan niệm gì\n",
            "answer: Màu sắc của mâm thường hay tuân theo ngũ hành. Các loại quả dùng thường mang các sắc màu theo quan niệm là có tính may mắn: đỏ (may mắn phú quý), vàng (sung túc)...\n",
            "prediction:0\n",
            "question_tok: ['Cách', 'trình', 'bày', 'm', '##âm', 'ng', '##ũ', 'quả', 'của', 'người', 'Bắc', 'theo', 'quan', 'niệm', 'gì']\n",
            "text_tok: ['M', '##àu', 'sắc', 'của', 'm', '##âm', 'thường', 'hay', 'tu', '##ân', 'theo', 'ng', '##ũ', 'hành', '.', 'Các', 'loại', 'quả', 'dùng', 'thường', 'mang', 'các', 'sắc', 'màu', 'theo', 'quan', 'niệm', 'là', 'có', 'tính', 'may', 'm', '##ắn', ':', 'đỏ', '(', 'may', 'm', '##ắn', 'ph', '##ú', 'quý', ')', ',', 'vàng', '(', 'sung', 'tú', '##c', ')', '.', '.', '.']\n",
            "\n",
            "question: Có bao nhiêu bệnh lây nhiễm qua đường tình dục không thể chữa khỏi hoàn toàn\n",
            "answer: Phòng ngừa là biện pháp chính trong việc phòng các bệnh lây qua đường tình dục không chữa được, chẳng hạn như HIV và Herpes sinh dục.\n",
            "prediction:0\n",
            "question_tok: ['Có', 'bao', 'n', '##hi', '##êu', 'bệnh', 'l', '##ây', 'nhiễm', 'qua', 'đường', 'tình', 'dục', 'không', 'thể', 'chữa', 'khỏi', 'hoàn', 'toàn']\n",
            "text_tok: ['Phòng', 'ng', '##ừa', 'là', 'bi', '##ện', 'pháp', 'chính', 'trong', 'việc', 'phòng', 'các', 'bệnh', 'l', '##ây', 'qua', 'đường', 'tình', 'dục', 'không', 'chữa', 'được', ',', 'chẳng', 'hạn', 'như', 'HIV', 'và', 'Her', '##pes', 'sinh', 'dục', '.']\n",
            "\n",
            "question: Tên gọi cổ xưa nhất của Malaysia là gì\n",
            "answer: Người Tamil cổ đại gọi bán đảo Mã Lai là \"Suvarnadvipa\" hay \"bán đảo hoàng kim\". Bán đảo được thể hiện trong bản đổ của Ptolemaeus với tên \"bán đảo hoàng kim\", ông thể hiện eo biển Malacca với tên \"Sinus Sabaricus\". Quan hệ mậu dịch với Trung Hoa và Ấn Độ được thiết lập trong thế kỷ 1 TCN. Những mảnh vỡ đồ gốm Trung Hoa phát hiện được tại Borneo có niên đại từ thế kỷ 1 sau khi nhà Hán khuếch trương về phía nam. Trong những thế kỷ đầu tiên của thiên niên kỷ thứ nhất, dân cư tại bán đảo Mã Lai tiếp nhận các tôn giáo Ấn Độ là Ấn Độ giáo và Phật giáo, chúng có tác động lớn về ngôn ngữ và văn hóa của dân cư tại Malaysia. Hệ thống chữ viết tiếng Phạn được sử dụng ngay từ thế kỷ 4.\n",
            "prediction:0\n",
            "question_tok: ['Tên', 'gọi', 'cổ', 'xưa', 'nhất', 'của', 'Malaysia', 'là', 'gì']\n",
            "text_tok: ['Người', 'Tamil', 'cổ', 'đại', 'gọi', 'bán', 'đảo', 'Mã', 'Lai', 'là', '\"', 'Suva', '##rna', '##d', '##vi', '##pa', '\"', 'hay', '\"', 'bán', 'đảo', 'hoàng', 'kim', '\"', '.', 'B', '##án', 'đảo', 'được', 'thể', 'hiện', 'trong', 'bản', 'đổ', 'của', 'Pt', '##ole', '##ma', '##eus', 'với', 'tên', '\"', 'bán', 'đảo', 'hoàng', 'kim', '\"', ',', 'ông', 'thể', 'hiện', 'eo', 'biển', 'Mala', '##cca', 'với', 'tên', '\"', 'Sin', '##us', 'Saba', '##ricu', '##s', '\"', '.', 'Quan', 'hệ', 'm', '##ậu', 'dịch', 'với', 'Trung', 'Hoa', 'và', 'Ấn', 'Độ', 'được', 'thiết', 'lập', 'trong', 'thế', 'kỷ', '1', 'TCN', '.', 'Những', 'm', '##ản', '##h', 'v', '##ỡ', 'đồ', 'g', '##ố', '##m', 'Trung', 'Hoa', 'phát', 'hiện', 'được', 'tại', 'Borneo', 'có', 'niên', 'đại', 'từ', 'thế', 'kỷ', '1', 'sau', 'khi', 'nhà', 'Hán', 'khu', '##ếc', '##h', 'tr', '##ương', 'về', 'phía', 'nam', '.', 'Trong', 'những', 'thế', 'kỷ', 'đầu', 'tiên', 'của', 'thiên', 'niên', 'kỷ', 'thứ', 'nhất', ',', 'dân', 'cư', 'tại', 'bán', 'đảo', 'Mã', 'Lai', 'tiếp', 'nhận', 'các', 'tôn', 'giáo', 'Ấn', 'Độ', 'là', 'Ấn', 'Độ', 'giáo', 'và', 'Phật', 'giáo', ',', 'chúng', 'có', 'tác', 'động', 'lớn', 'về', 'ngôn', 'ngữ', 'và', 'văn', 'hóa', 'của', 'dân', 'cư', 'tại', 'Malaysia', '.', 'Hệ', 'thống', 'chữ', 'viết', 'tiếng', 'Ph', '##ạn', 'được', 'sử', 'dụng', 'ngay', 'từ', 'thế', 'kỷ', '4', '.']\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWVuwQUsn6wS",
        "colab_type": "code",
        "outputId": "36a9e61b-88c6-4427-c5f2-e1de0f947804",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "test_dict = download('https://dl.challenge.zalo.ai/ZAC2019_VietnameseWikiQA/test.zip','test')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://dl.challenge.zalo.ai/ZAC2019_VietnameseWikiQA/test.zip\n",
            "262144/257843 [==============================] - 1s 2us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ovgkah8o5NA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pandas.io.json import json_normalize\n",
        "test = json_normalize(test_dict,'paragraphs',['__id__','question','title'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22fCbSSstfDg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_InputExamples = test.apply(lambda x: run_classifier.InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this example\n",
        "                                                                   text_a = x['question'], \n",
        "                                                                   text_b = x['text'], \n",
        "                                                                   label = 0), axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6qmQuT8xj_O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test = model_predict(estimator_from_tfhub, test_InputExamples)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "be8WjJaG0rIO",
        "colab_type": "code",
        "outputId": "42217f8b-5e1e-4d1c-ccd4-070d1158f5cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2678"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XC2395VMztM4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_sub = pd.merge(test,df_test,left_index=True,right_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ze01th4-5c4T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_final = df_sub[df_sub['pred']==1][['__id__','id']].reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHNpYkgw7odt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_final = df_final.rename(columns={'id':'answer','__id__':'test_id'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9QYw7M8Dry3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_final.to_csv('submission_5.csv',index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}